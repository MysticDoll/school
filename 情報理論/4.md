# 同時エントロピー
## 定義 3.4 同時エントロピー(結合エントロピー)
アルファベット $\cal{x}$ 上に値をとる確率変数$X$と  
アルファベット $\cal{y}$ 上に値をとる確率変数$Y$に対して,

$$ H(X,Y) = - \sum\_{x \in \cal{x} , y \in \cal{y}} p\_{XY}(x,y) \log p\_{XY} (x,y) $$

$X$と$Y$の同時エントロピーと呼ぶ

ただし、 $p\_{XY}(\cdot , \cdot)$ は$X$と$Y$の結合(同時)確率密度関数

つまり

$$ p\_{XY}(x,y) = P(X = x, Y = y) (x \in \cal{x}, y \in \cal{y}) $$

### 注
$H(X,Y)$は確率変数の対$(X,Y)$がどの値をとるかの不確かさを表す

### 復習 周辺分布
$x$値確率変数$X$と  
$y$値確率変数$Y$に対して,

それらの結合確率分布を $p\_{XY} (\cdot , \cdot )$とする  
このとき

$$
p\_{x} (x) = P(X = x)  \\\\
           = \sum\_{y \in \cal{y}} P(X = x, Y = y)  \\\\
           = \sum\_{y \in \cal{y}} p\_{XY} (x,y)
$$

同様に

$$ p\_{y} (y) = \sum\_{x \in \cal{x}} p\_{XY} (x,y) $$


# 3.4 条件付きエントロピー
## 定義3.5 条件付きエントロピー
以下

$X$をアルファベット $\cal{x}$ 上に値をとる確率変数  
$Y$をアルファベット $\cal{y}$ 上に値をとる確率変数とする,

$Y$の値が$y$だと知った後の$X$の値についての不確かさは

$$
H(X | Y = y) = - \sum\_{x \in \cal{x}} p\_{X|Y} (x|y) \log (p\_{X|Y} (x|y), y \in \cal{y}
$$

$Y$の値が何か知った後の$X$の値についての不確かさは

$$
H(X|Y) = \sum\_{y \in \cal{y}} p\_{Y} (y) H(X|Y =y)
$$

### 復習 条件付き確立
$P(X = x | Y = y) = p\_{X|Y} (x|y) = \frac{P(X = x, Y = y)}{P(Y = y)} = \frac{p\_{XY} (x,y)}{p\_{Y} (y)}$  

e.g. $Y = y$ であるときに $X = x$ であるような確立

#### 注
$p\_{X|Y} (\cdot | y)$ は確率関数, つまり

- $p\_{X|Y} (\cdot | y) \geq 0 $  
- $\sum\_{x \in \cal{x}} p\_{X|Y} (x|y) $

$$
\sum\_{x \in \cal{x}} p\_{X|Y} (x|y)
= \sum\_{x \in \cal{x}} \frac{P(X = x , Y = y)}{P(Y = y)}
= \frac{P(Y = y)}{P(Y = y)}
= 1
$$

#### 復習 独立性
$X,Y$が独立  
$\Leftrightarrow$  

$$
P(X = x | Y = y) = P(X = x) \forall x \in \cal{x} , y \in \cal{y}
$$

$\Leftrightarrow$

$$
P(X = x, Y = y) = P(X = x) P(Y =y) \forall x \in \cal{x} , y \in \cal{y}
$$

## 定理3.7
$$
H(X|Y) \leq H(X)
$$

等号成立は$X,Y$が独立の時

$$
∵ 
H(X|Y) = \sum\_{y \in \cal{y}} p\_{Y} (y) H(X | Y = y) \\\\
= \sum\_{y \in \cal{y}} p\_{Y} (y) (- \sum\_{x \in \cal{x}} p\_{X|Y} (x|y) \log p\_{X|Y} (x|y))
$$
