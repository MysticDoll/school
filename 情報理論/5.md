## 定理 3.8
$$
H(X,Y) = H(X) + H(Y|X) \\\\  
       = H(Y) + H(X|Y)
$$

### 証明
$$
H(X,Y) = - \sum\_{x \in \cal{x}} \sum\_{y \in \cal{y}} p\_{XY} (x, y) \log p\_{XY} (x, y) \\\\
       = - \sum\_{x \in \cal{x}} \sum\_{y \in \cal{y}} p\_{XY} (x, y) \log p\_{X} (x) - \sum\_{x \in \cal{x}} \sum\_{y \in \cal{y}} p\_{XY} (x, y) \log p\_{Y|X} (y,x) \\\\
       = H(X) + H(Y|X) \\\\
(∵ p\_{XY} (x,y) = p\_{X} (x) p\_{Y|X} (y|x) ) \\\\
$$

### 注(エントロピーのチェイン則)
確立変数 $X\_1, \dots , X\_n$ に対して 定理3.8を繰り返し用いることにより
$$
H(X\_1 , X\_2) = H(X\_1) + H(X\_2 | X\_1) \\\\
H(X\_1 , X\_2 , X\_3) = H(X\_1 , X\_2) + H(X\_3 | X\_1 , X\_2) \\\\
\vdots \\\\
H(X\_1, \dots , X\_{n-1}, X\_n) = H(X\_1 , \dots , X\_{n-1}) + H(H\_n | H\_1 , \dots , X\_{n-1})
$$
これらの辺々を足して
$$
H(X\_1 , \dots , X\_{n-1} , X\_n ) = H(X\_1) + H(X\_2 | X\_1) + H(X\_3 | X\_1 , X\_2 ) + H(X\_4 | X\_1 , X\_2 , X\_3) + \dots + H(X\_n | X\_1 , \dots , X\_{n-1})
$$

# 3.5 相互情報量
## 定義3.6
$I(X;Y) = H(X) + H(Y) - H(X,Y)$  
X, Y の相互情報量

## 定理3.9
$$
(i) I(X;Y) = I(Y;X) \\\\
(ii) I(X;Y) = H(X) - H(X|Y) \\\\
            = H(Y) - H(Y|X) \\\\
(iii) X, Y が独立 \Leftrightarrow I(X;Y) = 0 \\\\
(iv) 0 \leq I(X;Y) \leq \min \{H(X), H(Y)\}
$$

### 証明
$$
(ii) \\\\
I(X;Y) = H(X) + H(Y) - H(X,Y) (定義3.6)\\\\
       = H(X) + H(Y) - (H(Y) + H(X|Y))(定理3.8) \\\\
       = H(X) - H(X|Y)
$$

$$
(iv) \\\\
I(X;Y) = H(X) - H(X|Y) \geq 0 (定理3.7) \\\\
I(X;Y) = 0 \Leftrightarrow H(X) = H(X|Y) \Leftrightarrow X,Y が独立 (定理3.7) \\\\
I(X;Y) = H(X) - H(X|Y) \leq H(X) \\\\
I(Y;X) = H(Y) - H(Y|X) \leq H(Y)
$$
